{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'https://biendata.com/competition/airquality/bj/2018-03-01-0/2018-05-31-23/2k0d1d8'\n",
    "respones= requests.get(url)\n",
    "with open (\"bj_airquality.csv\",'w') as f:\n",
    "    f.write(respones.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "b_air = pd.read_csv(\"bj_airquality.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_air = b_air[b_air['time'] < '2018-05-14 00:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>station_id</th>\n",
       "      <th>time</th>\n",
       "      <th>PM25_Concentration</th>\n",
       "      <th>PM10_Concentration</th>\n",
       "      <th>NO2_Concentration</th>\n",
       "      <th>CO_Concentration</th>\n",
       "      <th>O3_Concentration</th>\n",
       "      <th>SO2_Concentration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2941450</td>\n",
       "      <td>dongsi_aq</td>\n",
       "      <td>2018-03-31 07:00:00</td>\n",
       "      <td>105.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>127.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2941451</td>\n",
       "      <td>tiantan_aq</td>\n",
       "      <td>2018-03-31 07:00:00</td>\n",
       "      <td>95.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>121.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2941452</td>\n",
       "      <td>guanyuan_aq</td>\n",
       "      <td>2018-03-31 07:00:00</td>\n",
       "      <td>95.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>123.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   station_id                 time  PM25_Concentration  \\\n",
       "0  2941450    dongsi_aq  2018-03-31 07:00:00               105.0   \n",
       "1  2941451   tiantan_aq  2018-03-31 07:00:00                95.0   \n",
       "2  2941452  guanyuan_aq  2018-03-31 07:00:00                95.0   \n",
       "\n",
       "   PM10_Concentration  NO2_Concentration  CO_Concentration  O3_Concentration  \\\n",
       "0               172.0               53.0               0.8             127.0   \n",
       "1               123.0               54.0               0.9             121.0   \n",
       "2               139.0               66.0               0.8             123.0   \n",
       "\n",
       "   SO2_Concentration  \n",
       "0               14.0  \n",
       "1               15.0  \n",
       "2               13.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_air.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>station_id</th>\n",
       "      <th>time</th>\n",
       "      <th>PM25_Concentration</th>\n",
       "      <th>PM10_Concentration</th>\n",
       "      <th>NO2_Concentration</th>\n",
       "      <th>CO_Concentration</th>\n",
       "      <th>O3_Concentration</th>\n",
       "      <th>SO2_Concentration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34647</th>\n",
       "      <td>2998338</td>\n",
       "      <td>xizhimenbei_aq</td>\n",
       "      <td>2018-05-13 23:00:00</td>\n",
       "      <td>126.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34648</th>\n",
       "      <td>2998339</td>\n",
       "      <td>nansanhuan_aq</td>\n",
       "      <td>2018-05-13 23:00:00</td>\n",
       "      <td>145.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34649</th>\n",
       "      <td>2998340</td>\n",
       "      <td>dongsihuan_aq</td>\n",
       "      <td>2018-05-13 23:00:00</td>\n",
       "      <td>172.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id      station_id                 time  PM25_Concentration  \\\n",
       "34647  2998338  xizhimenbei_aq  2018-05-13 23:00:00               126.0   \n",
       "34648  2998339   nansanhuan_aq  2018-05-13 23:00:00               145.0   \n",
       "34649  2998340   dongsihuan_aq  2018-05-13 23:00:00               172.0   \n",
       "\n",
       "       PM10_Concentration  NO2_Concentration  CO_Concentration  \\\n",
       "34647               137.0               72.0               1.0   \n",
       "34648               194.0               98.0               1.5   \n",
       "34649                 NaN              102.0               1.6   \n",
       "\n",
       "       O3_Concentration  SO2_Concentration  \n",
       "34647              34.0                5.0  \n",
       "34648               9.0                8.0  \n",
       "34649               5.0               14.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_air.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_air.columns = ['id', 'test_id', 'time', 'PM2.5', 'PM10','NO2', 'CO', 'O3', 'SO2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "def id(i):\n",
    "    return i.split('#')[0]\n",
    "\n",
    "test_station = pd.DataFrame(list(map(id, sample['test_id']))).drop_duplicates()\n",
    "test_station.columns = ['id']\n",
    "test_station = list(test_station['id'])\n",
    "\n",
    "bj_test_station = test_station[:35]\n",
    "ld_test_station = test_station[35:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function1(i, y):\n",
    "    b_air[b_air[\"test_id\"] == i][y].fillna(np.mean(b_air[b_air[\"test_id\"] == i][y]))\n",
    "    dataset = b_air[b_air[\"test_id\"] == i][y]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_cell():\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_cell_hidden_dim, \n",
    "                                        forget_bias=forget_bias, state_is_tuple=True, activation=tf.nn.softsign)\n",
    "    if keep_prob < 1.0:\n",
    "        cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "    return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(targets, predictions):\n",
    "    dividend= np.abs(np.array(targets) - np.array(predictions))\n",
    "    denominator = np.array(targets) + np.array(predictions)\n",
    "    \n",
    "    return 2 * np.mean(np.divide(dividend, denominator, out=np.zeros_like(dividend), where=denominator!=0, casting='unsafe'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaling(x):\n",
    "    x_np = np.asarray(x)\n",
    "    return (x_np-x_np.min()) / (x_np.max()-x_np.min() + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "rnn_cell_hidden_dim = 32   # 각 셀의 (hidden)출력 크기\n",
    "forget_bias = 1.0          # 망각편향(기본값 1.0)\n",
    "num_stacked_layers = 1     # stacked LSTM layers 개수\n",
    "keep_prob = 1.0            # dropout할 때 keep할 비율\n",
    "epoch_num = 1000           # 에폭 횟수(학습용전체데이터를 몇 회 반복해서 학습할 것인가 입력)\n",
    "learning_rate = 0.3        # 학습률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypothesis:  Tensor(\"rnn/transpose_1:0\", shape=(?, 7, 32), dtype=float32)\n",
      "학습을 시작합니다...\n",
      "epoch: 100, train_error: 0.533118486404419, test_error: 0.6355494260787964\n",
      "epoch: 200, train_error: 0.5057744383811951, test_error: 0.6039650440216064\n",
      "epoch: 300, train_error: 0.5039263963699341, test_error: 0.5959115624427795\n",
      "epoch: 400, train_error: 0.5063007473945618, test_error: 0.5967052578926086\n",
      "epoch: 500, train_error: 0.505075216293335, test_error: 0.5920022130012512\n",
      "epoch: 600, train_error: 0.5055768489837646, test_error: 0.5931032299995422\n",
      "epoch: 700, train_error: 0.506637454032898, test_error: 0.5920045375823975\n",
      "epoch: 800, train_error: 0.47614607214927673, test_error: 0.5568923950195312\n",
      "epoch: 900, train_error: 0.46139422059059143, test_error: 0.5354474782943726\n",
      "epoch: 1000, train_error: 0.4473627209663391, test_error: 0.5140455961227417\n",
      "hypothesis:  Tensor(\"rnn/transpose_1:0\", shape=(?, 7, 32), dtype=float32)\n",
      "학습을 시작합니다...\n",
      "epoch: 100, train_error: 0.6254305243492126, test_error: 0.7090994119644165\n",
      "epoch: 200, train_error: 0.5997052192687988, test_error: 0.664894700050354\n",
      "epoch: 300, train_error: 0.5909951329231262, test_error: 0.6510747671127319\n",
      "epoch: 400, train_error: 0.5939395427703857, test_error: 0.6519162058830261\n",
      "epoch: 500, train_error: 0.5487350821495056, test_error: 0.5738439559936523\n",
      "epoch: 600, train_error: 0.5478367805480957, test_error: 0.5661476850509644\n",
      "epoch: 700, train_error: 0.549577534198761, test_error: 0.5649458169937134\n",
      "epoch: 800, train_error: 0.5523063540458679, test_error: 0.5595201253890991\n",
      "epoch: 900, train_error: 0.5479244589805603, test_error: 0.5622509717941284\n",
      "epoch: 1000, train_error: 0.5471954345703125, test_error: 0.5625866651535034\n",
      "hypothesis:  Tensor(\"rnn/transpose_1:0\", shape=(?, 7, 32), dtype=float32)\n",
      "학습을 시작합니다...\n",
      "epoch: 100, train_error: 0.5185239911079407, test_error: 0.6164005994796753\n",
      "epoch: 200, train_error: 0.5187767148017883, test_error: 0.6129333972930908\n",
      "epoch: 300, train_error: 0.5186784863471985, test_error: 0.6054981350898743\n",
      "epoch: 400, train_error: 0.5185080170631409, test_error: 0.6048668622970581\n",
      "epoch: 500, train_error: 0.5187565088272095, test_error: 0.6060143113136292\n",
      "epoch: 600, train_error: 0.5193818807601929, test_error: 0.6068688035011292\n",
      "epoch: 700, train_error: 0.5202745795249939, test_error: 0.6074383854866028\n",
      "epoch: 800, train_error: 0.5179929137229919, test_error: 0.6057557463645935\n",
      "epoch: 900, train_error: 0.5196200609207153, test_error: 0.6056638360023499\n",
      "epoch: 1000, train_error: 0.5182555913925171, test_error: 0.6050076484680176\n",
      "hypothesis:  Tensor(\"rnn/transpose_1:0\", shape=(?, 7, 32), dtype=float32)\n",
      "학습을 시작합니다...\n",
      "epoch: 100, train_error: 0.5698534250259399, test_error: 0.6644296050071716\n",
      "epoch: 200, train_error: 0.56956946849823, test_error: 0.6619002223014832\n",
      "epoch: 300, train_error: 0.5695151686668396, test_error: 0.6591534614562988\n",
      "epoch: 400, train_error: 0.5699591040611267, test_error: 0.665123701095581\n",
      "epoch: 500, train_error: 0.5705340504646301, test_error: 0.6679890751838684\n",
      "epoch: 600, train_error: 0.5699779391288757, test_error: 0.6652370691299438\n",
      "epoch: 700, train_error: 0.5699764490127563, test_error: 0.6652280688285828\n",
      "epoch: 800, train_error: 0.5699763298034668, test_error: 0.6652278900146484\n",
      "epoch: 900, train_error: 0.5697355270385742, test_error: 0.6634718179702759\n",
      "epoch: 1000, train_error: 0.5699741244316101, test_error: 0.6652175188064575\n",
      "hypothesis:  Tensor(\"rnn/transpose_1:0\", shape=(?, 7, 32), dtype=float32)\n",
      "학습을 시작합니다...\n",
      "epoch: 100, train_error: 0.6070820093154907, test_error: 0.751484215259552\n",
      "epoch: 200, train_error: 0.6068984270095825, test_error: 0.7505782842636108\n",
      "epoch: 300, train_error: 0.6060335040092468, test_error: 0.7490447759628296\n",
      "epoch: 400, train_error: 0.6068198680877686, test_error: 0.7501609325408936\n",
      "epoch: 500, train_error: 0.6068034768104553, test_error: 0.7500705122947693\n",
      "epoch: 600, train_error: 0.606803297996521, test_error: 0.7500705122947693\n",
      "epoch: 700, train_error: 0.6068035960197449, test_error: 0.7500714659690857\n",
      "epoch: 800, train_error: 0.6067834496498108, test_error: 0.7499684691429138\n",
      "epoch: 900, train_error: 0.6068033576011658, test_error: 0.7500708699226379\n",
      "epoch: 1000, train_error: 0.6067838668823242, test_error: 0.7499616146087646\n",
      "hypothesis:  Tensor(\"rnn/transpose_1:0\", shape=(?, 7, 32), dtype=float32)\n",
      "학습을 시작합니다...\n",
      "epoch: 100, train_error: 0.6153120398521423, test_error: 0.716758131980896\n",
      "epoch: 200, train_error: 0.58663409948349, test_error: 0.6888951063156128\n",
      "epoch: 300, train_error: 0.5821866393089294, test_error: 0.6915767788887024\n",
      "epoch: 400, train_error: 0.5841538906097412, test_error: 0.6871708631515503\n",
      "epoch: 500, train_error: 0.5386396050453186, test_error: 0.6534260511398315\n",
      "epoch: 600, train_error: 0.544073224067688, test_error: 0.6477558016777039\n",
      "epoch: 700, train_error: 0.5434814691543579, test_error: 0.654194712638855\n",
      "epoch: 800, train_error: 0.5505884289741516, test_error: 0.6607567667961121\n",
      "epoch: 900, train_error: 0.5399848818778992, test_error: 0.6538534164428711\n",
      "epoch: 1000, train_error: 0.5405901074409485, test_error: 0.6520786285400391\n",
      "hypothesis:  Tensor(\"rnn/transpose_1:0\", shape=(?, 7, 32), dtype=float32)\n",
      "학습을 시작합니다...\n",
      "epoch: 100, train_error: 0.6607409119606018, test_error: 0.7511428594589233\n",
      "epoch: 200, train_error: 0.6366346478462219, test_error: 0.7169544100761414\n",
      "epoch: 300, train_error: 0.5800895094871521, test_error: 0.6111823320388794\n",
      "epoch: 400, train_error: 0.5727100968360901, test_error: 0.6019566655158997\n",
      "epoch: 500, train_error: 0.5636627078056335, test_error: 0.6008670926094055\n",
      "epoch: 600, train_error: 0.5552748441696167, test_error: 0.5741990804672241\n",
      "epoch: 700, train_error: 0.5530607104301453, test_error: 0.5786487460136414\n",
      "epoch: 800, train_error: 0.5489987134933472, test_error: 0.5708536505699158\n",
      "epoch: 900, train_error: 0.543553352355957, test_error: 0.5678357481956482\n",
      "epoch: 1000, train_error: 0.542696475982666, test_error: 0.5668804049491882\n",
      "hypothesis:  Tensor(\"rnn/transpose_1:0\", shape=(?, 7, 32), dtype=float32)\n",
      "학습을 시작합니다...\n",
      "epoch: 100, train_error: 0.7773488163948059, test_error: 0.807452917098999\n",
      "epoch: 200, train_error: 0.7422159910202026, test_error: 0.7697900533676147\n",
      "epoch: 300, train_error: 0.6793185472488403, test_error: 0.7254340052604675\n",
      "epoch: 400, train_error: 0.6722933650016785, test_error: 0.6976380348205566\n",
      "epoch: 500, train_error: 0.6687880158424377, test_error: 0.6934013962745667\n",
      "epoch: 600, train_error: 0.6777111291885376, test_error: 0.6866852045059204\n",
      "epoch: 700, train_error: 0.6694144010543823, test_error: 0.6942188739776611\n",
      "epoch: 800, train_error: 0.679220974445343, test_error: 0.7169723510742188\n",
      "epoch: 900, train_error: 0.6878728270530701, test_error: 0.7324366569519043\n",
      "epoch: 1000, train_error: 0.6923649311065674, test_error: 0.7232128977775574\n",
      "hypothesis:  Tensor(\"rnn/transpose_1:0\", shape=(?, 7, 32), dtype=float32)\n",
      "학습을 시작합니다...\n",
      "epoch: 100, train_error: nan, test_error: nan\n",
      "epoch: 200, train_error: nan, test_error: nan\n",
      "epoch: 300, train_error: nan, test_error: nan\n",
      "epoch: 400, train_error: nan, test_error: nan\n",
      "epoch: 500, train_error: nan, test_error: nan\n",
      "epoch: 600, train_error: nan, test_error: nan\n",
      "epoch: 700, train_error: nan, test_error: nan\n",
      "epoch: 800, train_error: nan, test_error: nan\n",
      "epoch: 900, train_error: nan, test_error: nan\n",
      "epoch: 1000, train_error: nan, test_error: nan\n",
      "hypothesis:  Tensor(\"rnn/transpose_1:0\", shape=(?, 7, 32), dtype=float32)\n",
      "학습을 시작합니다...\n",
      "epoch: 100, train_error: 0.634190022945404, test_error: 0.682353675365448\n",
      "epoch: 200, train_error: 0.6339005827903748, test_error: 0.6791207790374756\n",
      "epoch: 300, train_error: 0.6348132491111755, test_error: 0.6818122267723083\n",
      "epoch: 400, train_error: 0.6347332000732422, test_error: 0.6815178990364075\n",
      "epoch: 500, train_error: 0.6051838397979736, test_error: 0.6437447667121887\n",
      "epoch: 600, train_error: 0.6086645722389221, test_error: 0.6474210619926453\n",
      "epoch: 700, train_error: 0.6069443821907043, test_error: 0.6461141109466553\n",
      "epoch: 800, train_error: 0.6083913445472717, test_error: 0.6455055475234985\n",
      "epoch: 900, train_error: 0.6057817339897156, test_error: 0.6456863284111023\n",
      "epoch: 1000, train_error: 0.6070665717124939, test_error: 0.6392008662223816\n",
      "hypothesis:  Tensor(\"rnn/transpose_1:0\", shape=(?, 7, 32), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습을 시작합니다...\n",
      "epoch: 100, train_error: 0.4792934060096741, test_error: 0.5621533393859863\n",
      "epoch: 200, train_error: 0.4777783155441284, test_error: 0.5612008571624756\n",
      "epoch: 300, train_error: 0.47904708981513977, test_error: 0.5617205500602722\n",
      "epoch: 400, train_error: 0.4790411591529846, test_error: 0.561745285987854\n",
      "epoch: 500, train_error: 0.47855570912361145, test_error: 0.5604842901229858\n",
      "epoch: 600, train_error: 0.4790785312652588, test_error: 0.5617890357971191\n",
      "epoch: 700, train_error: 0.4790806174278259, test_error: 0.561794102191925\n",
      "epoch: 800, train_error: 0.479235976934433, test_error: 0.5621341466903687\n",
      "epoch: 900, train_error: 0.4790799021720886, test_error: 0.5617927312850952\n",
      "epoch: 1000, train_error: 0.47910138964653015, test_error: 0.5618190169334412\n",
      "hypothesis:  Tensor(\"rnn/transpose_1:0\", shape=(?, 7, 32), dtype=float32)\n",
      "학습을 시작합니다...\n",
      "epoch: 100, train_error: 0.6336760520935059, test_error: 0.7366752028465271\n",
      "epoch: 200, train_error: 0.6360079646110535, test_error: 0.738909125328064\n"
     ]
    }
   ],
   "source": [
    "submission = []\n",
    "y = 'O3'\n",
    "for idx,i in enumerate(bj_test_station):\n",
    "    mean = np.mean(pd.DataFrame(function1(i,y)))\n",
    "    aq1 = list(pd.DataFrame(function1(i,y)).fillna(round(mean,1))[y])\n",
    "    #aq = min_max_scaling(aq1)\n",
    "    \n",
    "    data=[]\n",
    "    for i in range(len(aq1)-48):\n",
    "        aq = aq1[i:i+48]\n",
    "        data.append(aq)\n",
    "    \n",
    "    data_X=[]\n",
    "    data_Y=[]\n",
    "    seq_length = 7\n",
    "    for i in range(len(data)-seq_length):\n",
    "        data_X.append(data[i:i+seq_length]) \n",
    "        data_Y.append(data[i+seq_length]) # i+seq_length번째 날 예측\n",
    "        \n",
    "        \n",
    "    train_size = int(len(data_Y) * 0.8)\n",
    "    # 데이터를 잘라 학습용 데이터 생성\n",
    "    trainX = data_X[:train_size]\n",
    "    trainY = data_Y[:train_size]\n",
    "\n",
    "    # 데이터를 잘라 테스트용 데이터 생성\n",
    "    testX = data_X[train_size:]\n",
    "    testY = data_Y[train_size:]\n",
    "    \n",
    "    trainX = np.reshape(trainX, [len(trainX),seq_length,48])\n",
    "    testX = np.reshape(testX, [len(testX),seq_length,48])\n",
    "    trainY = np.reshape(trainY,[len(trainY),48])\n",
    "    testY = np.reshape(testY,[len(testY),48])\n",
    "\n",
    "    # 모델\n",
    "    X = tf.placeholder(tf.float32, [None, seq_length, 48])\n",
    "    Y = tf.placeholder(tf.float32, [None, 48])\n",
    "\n",
    "    targets = tf.placeholder(tf.float32, [None, 48])\n",
    "    predictions = tf.placeholder(tf.float32, [None, 48])\n",
    "\n",
    "    # num_stacked_layers개의 층으로 쌓인 Stacked RNNs 생성\n",
    "    stackedRNNs = [lstm_cell() for _ in range(num_stacked_layers)]\n",
    "    multi_cells = tf.contrib.rnn.MultiRNNCell(stackedRNNs, state_is_tuple=True) if num_stacked_layers > 1 else lstm_cell()\n",
    "\n",
    "    # RNN Cell(여기서는 LSTM셀임)들을 연결\n",
    "    hypothesis, _states = tf.nn.dynamic_rnn(multi_cells, X, dtype=tf.float32)\n",
    "    print(\"hypothesis: \", hypothesis)\n",
    "\n",
    "    hypothesis = tf.contrib.layers.fully_connected(hypothesis[:, -1], 48, activation_fn=tf.nn.relu)\n",
    "    \n",
    "    # 손실함수로 평균제곱오차를 사용한다\n",
    "    loss = tf.reduce_sum(tf.square(hypothesis - Y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    train = optimizer.minimize(loss)\n",
    "    \n",
    "    #rmse = tf.sqrt(tf.reduce_mean(tf.squared_difference(targets, predictions)))\n",
    "    temp = tf.divide(tf.abs(targets-predictions), targets+predictions)\n",
    "    smape = 2*tf.reduce_mean(temp)\n",
    "    \n",
    "    train_error_summary = []\n",
    "    test_error_summary = []  # 테스트용 데이터의 오류를 중간 중간 기록한다\n",
    "    test_predict = ''        # 테스트용데이터로 예측한 결과\n",
    " \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # 학습한다\n",
    "    print('학습을 시작합니다...')\n",
    "\n",
    "    for epoch in range(epoch_num):\n",
    "        _, _loss = sess.run([train, loss], feed_dict={X: trainX, Y: trainY})\n",
    "        if ((epoch+1) % 100 == 0) or (epoch == epoch_num-1): # 100번째마다 또는 마지막 epoch인 경우\n",
    "\n",
    "            # 학습용데이터로 rmse오차를 구한다\n",
    "            train_predict = sess.run(hypothesis, feed_dict={X: trainX})\n",
    "            train_error = sess.run(smape, feed_dict={targets: trainY, predictions: train_predict})\n",
    "            train_error_summary.append(train_error)\n",
    " \n",
    "            # 테스트용데이터로 rmse오차를 구한다\n",
    "            test_predict = sess.run(hypothesis, feed_dict={X: testX})\n",
    "            test_error = sess.run(smape, feed_dict={targets: testY, predictions: test_predict})\n",
    "            test_error_summary.append(test_error)\n",
    "        \n",
    "            print(\"epoch: {}, train_error: {}, test_error: {}\".format(epoch+1,train_error,test_error))\n",
    "    \n",
    "    recent_data = np.reshape(data_X[len(data_X)-seq_length:][0], [-1,seq_length,48])\n",
    "    test_predict = sess.run(hypothesis, feed_dict={X: recent_data})\n",
    "    #print(\"test_predict\", test_predict)\n",
    "     \n",
    "    submission.append(test_predict[0])\n",
    "    \n",
    "    tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nan....\n",
    "#submission[8]\n",
    "submission[8] = np.array(np.mean(pd.DataFrame(submission).fillna(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([157.82441711, 159.66041565, 160.50166321, ...,  51.91577148,\n",
       "        49.79025269,  48.53936768])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PM25 = np.reshape(submission,-1)\n",
    "PM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([128.67303467, 128.09837341, 127.09113312, ..., 149.79852295,\n",
       "       149.59429932, 149.33416748])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PM10 = np.reshape(submission,-1)\n",
    "PM10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([91.8210907 , 89.62960052, 85.80215454, ..., 63.50445557,\n",
       "       53.46598816, 44.10897064])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O3 = np.reshape(submission,-1)\n",
    "O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25 = pd.DataFrame(PM25)\n",
    "pm10 = pd.DataFrame(PM10)\n",
    "o3 = pd.DataFrame(O3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25.to_csv('pm25_0513.csv')\n",
    "pm10.to_csv('pm10_0513.csv')\n",
    "o3.to_csv('o3_0513.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "p25 = pd.read_csv('ld_25_0513.csv')\n",
    "p10 = pd.read_csv('ld_10_0513.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25.columns = ['y']\n",
    "pm10.columns = ['y']\n",
    "o3.columns = ['y']\n",
    "p25.columns = ['a', 'y']\n",
    "p10.columns = ['a', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "624"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['PM2.5'] = list(pm25['y'])+(list(p25['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['PM10'] = list(pm10['y'])+(list(p10['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "sample['O3'][:1680] = list(o3['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zhiwuyuan_aq'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bj_test_station[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv('sample_0513.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"success\": true}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "files = {'files': open('sample_0513.csv','rb')}\n",
    "data = {\n",
    "    \"user_id\": \"dasolhwang\",\n",
    "    \"team_token\": \"53ed3560830874472182ca33790fe582ebd15bfb2f0506cb03d7757a9acc7480\",\n",
    "    \"description\": 'dasol_2018-05-13',\n",
    "    \"filename\": \"sample_0513.csv\",\n",
    "}\n",
    "url = 'https://biendata.com/competition/kdd_2018_submit/'\n",
    "response = requests.post(url, files=files, data=data)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
